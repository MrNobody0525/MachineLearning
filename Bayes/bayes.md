#朴素贝叶斯分类方法

##朴素贝叶斯：
朴素贝叶斯即对某数据计算它属于某类别的概率，选择概率高的一种作为其类别。具体可使用贝叶斯分类器。

##朴素贝叶斯的缺陷：
朴素贝叶斯为了减少样本的需求量，将特征视作独立的，所谓独立（independence） 指的是统计意义上的独立，即一个特征或者单词出现的可能性与它和其他单词相邻没有关系。
举个例子讲，假设单词bacon出现在unhealthy后面与出现在delicious后面的概率相同。当然，我们知 道这种假设并不正确，bacon常常出现在delicious附近，而很少出现在unhealthy附近，这个假设正 是朴素贝叶斯分类器中朴素（naive）一词的含义。
朴素贝叶斯分类器中的另一个假设是，每个特征同等重要。其实这个假设也有问题。 如果要判断留言板的留言是否得当，那么可能不需要看 完所有的1000个单词，而只需要看10～20个特征就足以做出判断了。尽管上述假设存在一些小的 瑕疵，但朴素贝叶斯的实际效果却很好。
##程序清单函数介绍：
###将词表转化为向量
	loadDataSet():加载词表，返回词条切分后的文档集合，以及类别标签集合
	createVocabList()：创建一个包含在所有文档中出现的不重复词的列表
	setOfWords2Vec()，该函数的输入参数为词汇表及某个文 档，输出的是文档向量，向量的每一元素为1或0，分别表示词汇表中的单词在输入文档中是否出 现
###训练算法
	trainNB0(trainMatrix,trainCategory):
代码函数中的输入参数为文档矩阵trainMatrix，以及由每篇文档类别标签所构成的向量trainCategory,函数 会返回两个向量和一个概率。  
###朴素贝叶斯分类函数
	classifyNB(vec2Classify,p0Vec,p1Vec,pClass1):
	testingNB():
有4个输入：要分类的向量vec2Classify以及使用函数trainNB0()计算得到的三个概率。然后，比较类别的概率返回大概率对应的类别标签。

	bagOfWords2VecMN(vocabList,inputSet):
 
准备朴素贝叶斯词袋模型

###然后就可以玩实例了
